### 锁的优化部分
#### 首先要说明，在高并发情况下，不加锁==不安全，这种是不会有人去做的，头铁。既然加了锁，那么性能是肯定会要下降的，为了将这种副作用降低，需要一些措施来帮助我们提高锁的性能
#### 1.减少锁的持有时间
显而易见的一种，在锁的竞争中，如果单个线程的持有时间越长，那么锁的竞争肯定就会越激烈。想象一下上厕所，就很好理解了，里面的人一直不出来，占用着锁，外面的人很急想进去。如果每个线程占用锁的时间都很长，那么总体花费的时间就会变长。
##### 运用到实际中，也就是尽量只在必要的时候同步。如果并发量很大，又对整个方法都同步，那么可想而知，会导致等待线程数量大大增加。
#### 2.减少锁的粒度
减少锁的粒度，就是缩小锁定对象的范围，从而降低锁冲突的可能性，提高性能

举个例子就很好理解了，concurrentHashmap，这种就是高性能的HashMap
##### 2.1 concurrenteHashMap的实现原理
这个也是面试的时候经常问的。首先，对于HashMap来说，最主要的两个方法put和get。一种最容易想到的方案就是对整个HashMap加锁，从而得到一个线程安全的对象，但是这样的话锁的粒度太大了。所以concurrentHashMap类，它的内部时进一步细分了，分成了若干个小的HashMap，称之为“段”，默认是16个段。如果要在concurrentHashMap中增加一个新的KV，并不是对整个HashMap加锁，而是先计算它的hashcode，放进某个“段”中，然后对该“段”加锁。所以这就是concurrenteHashMap的分段式锁。

在高并发条件下，如果多个线程同时进行put，只要被加入的KV不存放在同一个段中，线程就可以做到真正的并行。由于默认是16个段，所以如果够幸运的话，能够解锁16个线程同时进行写操作，从而大大的提高了性能
#### 3.读写分离来替换独占锁
这个很好理解，数据库和java都践行了这种思想。

如果说减少锁的粒度是通过拆分数据结构，那么读写分离就是拆分功能

之前学习读写锁的时候已经讲过了，在实际开发中，读操作是远远大于写操作的。读操作不会影响数据的一致性，但是写操作会，那么直接来个读写锁，读的时候不同步，写的时候同步就完事了。这种可以很显然的提高系统的并发能力

#### 4.锁分离
将读写锁的思想进一步延伸，就是锁分离。依据应用程序的功能特点，使用类似的分离思想，将独占锁进行分离。举个例子，LinkedBlockingQueue。

LinkedBlockingQueue的take和put方法，这两个是对队列的首尾端进行的操作。如果是普通的独占锁，那么很显然的，take和put不可能做到真正的并发，在运行的时候会等待对方释放锁。

所以LinkedBlockingQueue用了两把锁，两把不同的锁，take和put一人一把，相互不影响，只会存在take和take，put和put之间的竞争，不会存在take和put之间的竞争

##### 简而言之，就是多来几把锁